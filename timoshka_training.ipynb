{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение wake word \"Тимошка\" для openWakeWord\n",
    "\n",
    "Полный пайплайн: Russian Piper TTS → Voice Conversion (FreeVC24) → openWakeWord Training → TFLite\n",
    "\n",
    "**Требования:** Google Colab Pro с A100 (рекомендуется). Время: 3-6 часов.\n",
    "\n",
    "## Этапы\n",
    "1. Установка зависимостей\n",
    "2. Генерация TTS-сэмплов (Piper, русские голоса)\n",
    "3. Подготовка целевых голосов из Common Voice\n",
    "4. Voice conversion (FreeVC24)\n",
    "5. Скачивание негативных данных (ACAV100M)\n",
    "6. Обучение openWakeWord\n",
    "7. Конвертация в TFLite\n",
    "8. Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1: Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Клонируем репозитории\n",
    "cd /content\n",
    "\n",
    "if [ ! -d \"openWakeWord\" ]; then\n",
    "    git clone https://github.com/dscripka/openWakeWord.git\n",
    "fi\n",
    "\n",
    "if [ ! -d \"piper-sample-generator\" ]; then\n",
    "    git clone https://github.com/rhasspy/piper-sample-generator.git\n",
    "fi\n",
    "\n",
    "echo \"Done cloning repos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Устанавливаем зависимости\n",
    "pip install -q piper-phonemize\n",
    "pip install -q webrtcvad\n",
    "pip install -q -e /content/openWakeWord\n",
    "pip install -q -e /content/piper-sample-generator\n",
    "pip install -q coqui-tts\n",
    "pip install -q mutagen==1.47.0\n",
    "pip install -q torchinfo==1.8.0\n",
    "pip install -q torchmetrics==1.2.0\n",
    "pip install -q speechbrain==0.5.14\n",
    "pip install -q audiomentations==0.33.0\n",
    "pip install -q torch-audiomentations==0.11.0\n",
    "pip install -q acoustics==0.2.6\n",
    "pip install -q pronouncing==0.2.0\n",
    "pip install -q datasets==2.14.6\n",
    "pip install -q deep-phonemizer==0.0.19\n",
    "pip install -q tensorflow-cpu==2.8.1\n",
    "pip install -q tensorflow_probability==0.16.0\n",
    "pip install -q onnx_tf==1.10.0\n",
    "\n",
    "echo \"\\nAll dependencies installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Рабочие директории\n",
    "BASE_DIR = \"/content/timoshka\"\n",
    "VOICES_DIR = os.path.join(BASE_DIR, \"piper_voices\")\n",
    "TTS_POSITIVE_DIR = os.path.join(BASE_DIR, \"tts_positive\")\n",
    "TTS_NEGATIVE_DIR = os.path.join(BASE_DIR, \"tts_negative\")\n",
    "VOICE_TARGETS_DIR = os.path.join(BASE_DIR, \"voice_targets\")\n",
    "VC_POSITIVE_DIR = os.path.join(BASE_DIR, \"vc_positive\")\n",
    "VC_NEGATIVE_DIR = os.path.join(BASE_DIR, \"vc_negative\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
    "\n",
    "for d in [\n",
    "    BASE_DIR, VOICES_DIR, TTS_POSITIVE_DIR, TTS_NEGATIVE_DIR,\n",
    "    VOICE_TARGETS_DIR, VC_POSITIVE_DIR, VC_NEGATIVE_DIR, OUTPUT_DIR,\n",
    "]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2: Генерация TTS-сэмплов (Piper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Скачиваем русские голоса Piper\n",
    "cd /content/timoshka/piper_voices\n",
    "\n",
    "VOICES=(\n",
    "    \"ru/ru_RU/irina/medium/ru_RU-irina-medium\"\n",
    "    \"ru/ru_RU/ruslan/medium/ru_RU-ruslan-medium\"\n",
    "    \"ru/ru_RU/denis/medium/ru_RU-denis-medium\"\n",
    "    \"ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium\"\n",
    ")\n",
    "\n",
    "BASE_URL=\"https://huggingface.co/rhasspy/piper-voices/resolve/main\"\n",
    "\n",
    "for voice in \"${VOICES[@]}\"; do\n",
    "    name=$(basename $voice)\n",
    "    if [ ! -f \"${name}.onnx\" ]; then\n",
    "        echo \"Downloading ${name}...\"\n",
    "        wget -q -O \"${name}.onnx\" \"${BASE_URL}/${voice}.onnx?download=true\"\n",
    "        wget -q -O \"${name}.onnx.json\" \"${BASE_URL}/${voice}.onnx.json?download=true\"\n",
    "    else\n",
    "        echo \"${name} already downloaded\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"\\nAll voices downloaded:\"\n",
    "ls -la *.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# Позитивные сэмплы: \"тимошка\"\n",
    "# 250 сэмплов на каждый из 4 голосов = 1000 базовых\n",
    "\n",
    "voices = sorted(glob.glob(os.path.join(VOICES_DIR, \"*.onnx\")))\n",
    "print(f\"Found {len(voices)} Piper voices\")\n",
    "\n",
    "POSITIVE_PHRASE = \"тимошка\"\n",
    "SAMPLES_PER_VOICE = 250\n",
    "\n",
    "for voice_path in voices:\n",
    "    voice_name = os.path.basename(voice_path).replace(\".onnx\", \"\")\n",
    "    out_dir = os.path.join(TTS_POSITIVE_DIR, voice_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    existing = len(glob.glob(os.path.join(out_dir, \"*.wav\")))\n",
    "    if existing >= SAMPLES_PER_VOICE:\n",
    "        print(f\"  {voice_name}: {existing} samples already exist, skipping\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Generating {SAMPLES_PER_VOICE} positive samples with {voice_name}...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"/content/piper-sample-generator/generate_samples.py\",\n",
    "        POSITIVE_PHRASE,\n",
    "        \"--model\", voice_path,\n",
    "        \"--max-samples\", str(SAMPLES_PER_VOICE),\n",
    "        \"--output-dir\", out_dir,\n",
    "    ], check=True)\n",
    "\n",
    "    generated = len(glob.glob(os.path.join(out_dir, \"*.wav\")))\n",
    "    print(f\"    Generated: {generated}\")\n",
    "\n",
    "total = sum(\n",
    "    len(glob.glob(os.path.join(TTS_POSITIVE_DIR, d, \"*.wav\")))\n",
    "    for d in os.listdir(TTS_POSITIVE_DIR)\n",
    "    if os.path.isdir(os.path.join(TTS_POSITIVE_DIR, d))\n",
    ")\n",
    "print(f\"\\nTotal positive TTS samples: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Негативные (adversarial) сэмплы: фонетически похожие слова\n",
    "\n",
    "NEGATIVE_PHRASES = [\n",
    "    \"тимофей\", \"кошка\", \"мошка\", \"ромашка\", \"матрёшка\",\n",
    "    \"гармошка\", \"картошка\", \"окрошка\", \"мишка\", \"мышка\",\n",
    "    \"тишка\", \"тимоша\", \"тимошенко\", \"морошка\", \"крошка\",\n",
    "    \"дорожка\", \"ложка\", \"тишина\", \"тёмушка\",\n",
    "]\n",
    "\n",
    "NEGATIVE_SAMPLES_PER_PHRASE_PER_VOICE = 50\n",
    "\n",
    "for phrase in NEGATIVE_PHRASES:\n",
    "    for voice_path in voices:\n",
    "        voice_name = os.path.basename(voice_path).replace(\".onnx\", \"\")\n",
    "        # Use safe directory name for phrases with special chars\n",
    "        safe_phrase = phrase.replace(\"ё\", \"е\")\n",
    "        out_dir = os.path.join(TTS_NEGATIVE_DIR, f\"{safe_phrase}_{voice_name}\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        existing = len(glob.glob(os.path.join(out_dir, \"*.wav\")))\n",
    "        if existing >= NEGATIVE_SAMPLES_PER_PHRASE_PER_VOICE:\n",
    "            continue\n",
    "\n",
    "        subprocess.run([\n",
    "            \"python3\", \"/content/piper-sample-generator/generate_samples.py\",\n",
    "            phrase,\n",
    "            \"--model\", voice_path,\n",
    "            \"--max-samples\", str(NEGATIVE_SAMPLES_PER_PHRASE_PER_VOICE),\n",
    "            \"--output-dir\", out_dir,\n",
    "        ], check=True)\n",
    "\n",
    "    print(f\"  Done: {phrase}\")\n",
    "\n",
    "# Count totals\n",
    "total_neg = 0\n",
    "for root, dirs, files in os.walk(TTS_NEGATIVE_DIR):\n",
    "    total_neg += len([f for f in files if f.endswith(\".wav\")])\n",
    "\n",
    "print(f\"\\nTotal negative TTS samples: {total_neg}\")\n",
    "print(f\"Expected: {len(NEGATIVE_PHRASES)} phrases × {len(voices)} voices × {NEGATIVE_SAMPLES_PER_PHRASE_PER_VOICE} = {len(NEGATIVE_PHRASES) * len(voices) * NEGATIVE_SAMPLES_PER_PHRASE_PER_VOICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слушаем несколько сэмплов для проверки\n",
    "import IPython.display as ipd\n",
    "\n",
    "sample_files = glob.glob(os.path.join(TTS_POSITIVE_DIR, \"*/*.wav\"))[:3]\n",
    "for f in sample_files:\n",
    "    print(f\"Playing: {os.path.basename(os.path.dirname(f))}/{os.path.basename(f)}\")\n",
    "    ipd.display(ipd.Audio(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 3: Подготовка целевых голосов (Common Voice)\n",
    "\n",
    "**Инструкция:**\n",
    "1. Скачайте Russian Common Voice dataset с https://commonvoice.mozilla.org/datasets\n",
    "2. Загрузите архив в Google Drive или напрямую в Colab\n",
    "3. Распакуйте в `/content/common_voice_ru/`\n",
    "\n",
    "Или используйте HuggingFace datasets (ячейка ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант A: Скачать через HuggingFace datasets API\n",
    "# Если у вас есть HF token, раскомментируйте и запустите:\n",
    "\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "print(\"Loading Russian Common Voice from HuggingFace...\")\n",
    "print(\"(This may take a while on first download)\")\n",
    "\n",
    "cv_dataset = load_dataset(\n",
    "    \"mozilla-foundation/common_voice_16_1\",\n",
    "    \"ru\",\n",
    "    split=\"validated\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(f\"Total validated clips: {len(cv_dataset)}\")\n",
    "\n",
    "# Pick one clip per unique client_id for speaker diversity\n",
    "seen_speakers = set()\n",
    "selected = []\n",
    "\n",
    "# Shuffle for randomness\n",
    "indices = list(range(len(cv_dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "MAX_TARGETS = 100\n",
    "\n",
    "for idx in indices:\n",
    "    if len(selected) >= MAX_TARGETS:\n",
    "        break\n",
    "    row = cv_dataset[idx]\n",
    "    speaker = row[\"client_id\"]\n",
    "    if speaker in seen_speakers:\n",
    "        continue\n",
    "\n",
    "    audio = row[\"audio\"]\n",
    "    duration = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    # Filter: 3-15 seconds\n",
    "    if duration < 3.0 or duration > 15.0:\n",
    "        continue\n",
    "\n",
    "    seen_speakers.add(speaker)\n",
    "    selected.append(row)\n",
    "\n",
    "print(f\"Selected {len(selected)} unique speakers\")\n",
    "\n",
    "# Save as 16kHz mono WAV\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "for i, row in enumerate(selected):\n",
    "    audio = row[\"audio\"]\n",
    "    waveform = torch.tensor(audio[\"array\"]).unsqueeze(0).float()\n",
    "    sr = audio[\"sampling_rate\"]\n",
    "\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    out_path = os.path.join(VOICE_TARGETS_DIR, f\"speaker_{i:04d}.wav\")\n",
    "    torchaudio.save(out_path, waveform, 16000)\n",
    "\n",
    "print(f\"Saved {len(selected)} target voice files to {VOICE_TARGETS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант B: Если вы скачали Common Voice вручную и загрузили в Colab\n",
    "# Раскомментируйте и укажите путь:\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, '/content')\n",
    "# from voice_convert import prepare_common_voice_targets\n",
    "#\n",
    "# prepare_common_voice_targets(\n",
    "#     cv_dir=\"/content/common_voice_ru\",\n",
    "#     output_dir=VOICE_TARGETS_DIR,\n",
    "#     max_clips=100,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем количество целевых голосов\n",
    "target_files = sorted(glob.glob(os.path.join(VOICE_TARGETS_DIR, \"*.wav\")))\n",
    "print(f\"Target voice files: {len(target_files)}\")\n",
    "\n",
    "if len(target_files) < 10:\n",
    "    print(\"WARNING: Too few target voices! Aim for 50-100 for good results.\")\n",
    "elif len(target_files) < 50:\n",
    "    print(\"OK: Minimum viable, but 100 targets will produce better results.\")\n",
    "else:\n",
    "    print(\"Good: Sufficient target voices for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 4: Voice Conversion (FreeVC24)\n",
    "\n",
    "Это самый долгий этап (~3-5 часов на A100).\n",
    "\n",
    "Каждый TTS-сэмпл конвертируется с каждым целевым голосом → N×M результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Загружаем модель FreeVC24\n",
    "print(\"Loading FreeVC24 model...\")\n",
    "vc_model = TTS(\"voice_conversion_models/multilingual/vctk/freevc24\").to(\"cuda\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_voice_conversion(source_dir, output_dir, target_files, label=\"\"):\n",
    "    \"\"\"Convert all WAVs in source_dir with all target voices.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Collect all source WAVs (may be in subdirectories)\n",
    "    source_files = []\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for f in files:\n",
    "            if f.endswith(\".wav\"):\n",
    "                source_files.append(os.path.join(root, f))\n",
    "    source_files.sort()\n",
    "\n",
    "    total = len(source_files) * len(target_files)\n",
    "    print(f\"{label}Sources: {len(source_files)}, Targets: {len(target_files)}, Total: {total}\")\n",
    "\n",
    "    done = 0\n",
    "    skipped = 0\n",
    "    errors = 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for src in source_files:\n",
    "        src_name = Path(src).stem\n",
    "        # Include parent dir name to avoid collisions\n",
    "        parent_name = Path(src).parent.name\n",
    "        prefix = f\"{parent_name}_{src_name}\" if parent_name != Path(source_dir).name else src_name\n",
    "\n",
    "        for tgt in target_files:\n",
    "            tgt_name = Path(tgt).stem\n",
    "            out_path = os.path.join(output_dir, f\"{prefix}_vc{tgt_name}.wav\")\n",
    "\n",
    "            if os.path.exists(out_path):\n",
    "                skipped += 1\n",
    "                done += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                vc_model.voice_conversion_to_file(\n",
    "                    source_wav=src,\n",
    "                    target_wav=tgt,\n",
    "                    file_path=out_path,\n",
    "                )\n",
    "                done += 1\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                done += 1\n",
    "                if errors <= 5:\n",
    "                    print(f\"  Error: {prefix} + {tgt_name}: {e}\")\n",
    "\n",
    "            if done % 500 == 0:\n",
    "                elapsed = time.time() - t0\n",
    "                rate = (done - skipped) / max(elapsed, 1)\n",
    "                eta = (total - done) / max(rate, 0.01)\n",
    "                print(\n",
    "                    f\"  [{done}/{total}] {rate:.1f}/s, \"\n",
    "                    f\"ETA {eta/60:.0f}min, errors={errors}\"\n",
    "                )\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(\n",
    "        f\"  Done: {done - skipped - errors} converted, \"\n",
    "        f\"{skipped} skipped, {errors} errors in {elapsed/60:.1f}min\\n\"\n",
    "    )\n",
    "    return done - skipped - errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем позитивные сэмплы\n",
    "print(\"=\" * 60)\n",
    "print(\"POSITIVE SAMPLES: Voice Conversion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_positive = run_voice_conversion(\n",
    "    source_dir=TTS_POSITIVE_DIR,\n",
    "    output_dir=VC_POSITIVE_DIR,\n",
    "    target_files=target_files,\n",
    "    label=\"[POSITIVE] \",\n",
    ")\n",
    "\n",
    "print(f\"Total positive voice-converted samples: {n_positive}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем негативные сэмплы\n",
    "print(\"=\" * 60)\n",
    "print(\"NEGATIVE SAMPLES: Voice Conversion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_negative = run_voice_conversion(\n",
    "    source_dir=TTS_NEGATIVE_DIR,\n",
    "    output_dir=VC_NEGATIVE_DIR,\n",
    "    target_files=target_files,\n",
    "    label=\"[NEGATIVE] \",\n",
    ")\n",
    "\n",
    "print(f\"Total negative voice-converted samples: {n_negative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ресэмплим всё в 16kHz mono (на всякий случай)\n",
    "import torchaudio\n",
    "\n",
    "def ensure_16k_mono(directory):\n",
    "    \"\"\"Ensure all WAVs in directory are 16kHz mono.\"\"\"\n",
    "    files = glob.glob(os.path.join(directory, \"*.wav\"))\n",
    "    fixed = 0\n",
    "    for f in files:\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(f)\n",
    "            changed = False\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "                changed = True\n",
    "            if sr != 16000:\n",
    "                waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "                changed = True\n",
    "            if changed:\n",
    "                torchaudio.save(f, waveform, 16000)\n",
    "                fixed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  Error resampling {f}: {e}\")\n",
    "    return fixed\n",
    "\n",
    "print(\"Checking positive samples...\")\n",
    "fixed_pos = ensure_16k_mono(VC_POSITIVE_DIR)\n",
    "print(f\"  Fixed {fixed_pos} files\")\n",
    "\n",
    "print(\"Checking negative samples...\")\n",
    "fixed_neg = ensure_16k_mono(VC_NEGATIVE_DIR)\n",
    "print(f\"  Fixed {fixed_neg} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слушаем несколько конвертированных сэмплов\n",
    "vc_samples = glob.glob(os.path.join(VC_POSITIVE_DIR, \"*.wav\"))[:3]\n",
    "for f in vc_samples:\n",
    "    print(f\"Playing: {os.path.basename(f)}\")\n",
    "    ipd.display(ipd.Audio(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 5: Скачивание данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content/timoshka\n",
    "\n",
    "# ACAV100M features (~6 GB) — негативные данные для обучения\n",
    "if [ ! -f \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\" ]; then\n",
    "    echo \"Downloading ACAV100M features (~6 GB)...\"\n",
    "    wget -q --show-progress \\\n",
    "        https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
    "else\n",
    "    echo \"ACAV100M features already downloaded\"\n",
    "fi\n",
    "\n",
    "# Validation set (~30 MB)\n",
    "if [ ! -f \"validation_set_features.npy\" ]; then\n",
    "    echo \"Downloading validation set...\"\n",
    "    wget -q --show-progress \\\n",
    "        https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
    "else\n",
    "    echo \"Validation set already downloaded\"\n",
    "fi\n",
    "\n",
    "echo \"\\nData files:\"\n",
    "ls -lh *.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content/timoshka\n",
    "\n",
    "# MIT Room Impulse Responses для реверберации\n",
    "if [ ! -d \"mit_rirs\" ]; then\n",
    "    echo \"Downloading MIT RIRs...\"\n",
    "    mkdir -p mit_rirs\n",
    "    wget -q --show-progress -O mit_rirs.zip \\\n",
    "        https://mcdermottlab.mit.edu/Reverb/IRMAudio/Audio.zip\n",
    "    unzip -q mit_rirs.zip -d mit_rirs/ 2>/dev/null || true\n",
    "    rm -f mit_rirs.zip\n",
    "    echo \"MIT RIRs downloaded\"\n",
    "else\n",
    "    echo \"MIT RIRs already present\"\n",
    "fi\n",
    "\n",
    "# Background noise: audioset_16k subset + FMA\n",
    "# Using a smaller subset for Colab\n",
    "if [ ! -d \"audioset_16k\" ]; then\n",
    "    echo \"Downloading AudioSet background noise subset...\"\n",
    "    mkdir -p audioset_16k\n",
    "    # Use the openWakeWord-provided noise subset if available\n",
    "    wget -q --show-progress -O audioset_16k.tar.gz \\\n",
    "        https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/audioset_16k_sample.tar.gz \\\n",
    "        2>/dev/null || echo \"Note: AudioSet subset not found. Training will use ACAV100M as primary negative data.\"\n",
    "    if [ -f audioset_16k.tar.gz ]; then\n",
    "        tar -xzf audioset_16k.tar.gz -C audioset_16k/ 2>/dev/null || true\n",
    "        rm -f audioset_16k.tar.gz\n",
    "    fi\n",
    "fi\n",
    "\n",
    "mkdir -p fma\n",
    "echo \"Background data ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 6: Обучение openWakeWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Подсчёт сэмплов\n",
    "n_pos = len(glob.glob(os.path.join(VC_POSITIVE_DIR, \"*.wav\")))\n",
    "n_neg = len(glob.glob(os.path.join(VC_NEGATIVE_DIR, \"*.wav\")))\n",
    "# Также добавляем оригинальные TTS-сэмплы\n",
    "n_pos_tts = sum(\n",
    "    len(glob.glob(os.path.join(TTS_POSITIVE_DIR, d, \"*.wav\")))\n",
    "    for d in os.listdir(TTS_POSITIVE_DIR)\n",
    "    if os.path.isdir(os.path.join(TTS_POSITIVE_DIR, d))\n",
    ")\n",
    "n_neg_tts = 0\n",
    "for root, dirs, files in os.walk(TTS_NEGATIVE_DIR):\n",
    "    n_neg_tts += len([f for f in files if f.endswith(\".wav\")])\n",
    "\n",
    "print(f\"Voice-converted positive: {n_pos}\")\n",
    "print(f\"Voice-converted negative: {n_neg}\")\n",
    "print(f\"TTS positive (original):  {n_pos_tts}\")\n",
    "print(f\"TTS negative (original):  {n_neg_tts}\")\n",
    "print(f\"Total positive: {n_pos + n_pos_tts}\")\n",
    "print(f\"Total negative: {n_neg + n_neg_tts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем все позитивные сэмплы в одну директорию\n",
    "import shutil\n",
    "\n",
    "ALL_POSITIVE_DIR = os.path.join(BASE_DIR, \"all_positive\")\n",
    "ALL_NEGATIVE_DIR = os.path.join(BASE_DIR, \"all_negative\")\n",
    "os.makedirs(ALL_POSITIVE_DIR, exist_ok=True)\n",
    "os.makedirs(ALL_NEGATIVE_DIR, exist_ok=True)\n",
    "\n",
    "# Symlink positive: VC + original TTS\n",
    "for f in glob.glob(os.path.join(VC_POSITIVE_DIR, \"*.wav\")):\n",
    "    dst = os.path.join(ALL_POSITIVE_DIR, os.path.basename(f))\n",
    "    if not os.path.exists(dst):\n",
    "        os.symlink(f, dst)\n",
    "\n",
    "for root, dirs, files in os.walk(TTS_POSITIVE_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith(\".wav\"):\n",
    "            src = os.path.join(root, f)\n",
    "            parent = os.path.basename(root)\n",
    "            dst = os.path.join(ALL_POSITIVE_DIR, f\"tts_{parent}_{f}\")\n",
    "            if not os.path.exists(dst):\n",
    "                os.symlink(src, dst)\n",
    "\n",
    "# Symlink negative: VC + original TTS\n",
    "for f in glob.glob(os.path.join(VC_NEGATIVE_DIR, \"*.wav\")):\n",
    "    dst = os.path.join(ALL_NEGATIVE_DIR, os.path.basename(f))\n",
    "    if not os.path.exists(dst):\n",
    "        os.symlink(f, dst)\n",
    "\n",
    "for root, dirs, files in os.walk(TTS_NEGATIVE_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith(\".wav\"):\n",
    "            src = os.path.join(root, f)\n",
    "            parent = os.path.basename(root)\n",
    "            dst = os.path.join(ALL_NEGATIVE_DIR, f\"tts_{parent}_{f}\")\n",
    "            if not os.path.exists(dst):\n",
    "                os.symlink(src, dst)\n",
    "\n",
    "total_pos = len(glob.glob(os.path.join(ALL_POSITIVE_DIR, \"*.wav\")))\n",
    "total_neg = len(glob.glob(os.path.join(ALL_NEGATIVE_DIR, \"*.wav\")))\n",
    "print(f\"All positive samples: {total_pos}\")\n",
    "print(f\"All negative samples: {total_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём конфиг для обучения\n",
    "# openWakeWord train.py ожидает конкретную структуру директорий;\n",
    "# мы создадим нужные симлинки в output_dir\n",
    "\n",
    "TRAINING_DIR = os.path.join(BASE_DIR, \"training\")\n",
    "os.makedirs(TRAINING_DIR, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"model_name\": \"timoshka\",\n",
    "    \"target_phrase\": [\"тимошка\"],\n",
    "    \"custom_negative_phrases\": [],\n",
    "\n",
    "    # We supply pre-generated clips, set to 0\n",
    "    \"n_samples\": 0,\n",
    "    \"n_samples_val\": 0,\n",
    "\n",
    "    \"augmentation_rounds\": 1,\n",
    "    \"augmentation_batch_size\": 16,\n",
    "\n",
    "    \"piper_sample_generator_path\": \"/content/piper-sample-generator\",\n",
    "    \"output_dir\": TRAINING_DIR,\n",
    "\n",
    "    \"rir_paths\": [os.path.join(BASE_DIR, \"mit_rirs\")],\n",
    "    \"background_paths\": [\n",
    "        os.path.join(BASE_DIR, \"audioset_16k\"),\n",
    "        os.path.join(BASE_DIR, \"fma\"),\n",
    "    ],\n",
    "    \"background_paths_duplication_rate\": [1],\n",
    "\n",
    "    \"feature_data_files\": {\n",
    "        \"ACAV100M_sample\": os.path.join(\n",
    "            BASE_DIR, \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
    "        ),\n",
    "    },\n",
    "    \"false_positive_validation_data_path\": os.path.join(\n",
    "        BASE_DIR, \"validation_set_features.npy\"\n",
    "    ),\n",
    "\n",
    "    \"batch_n_per_class\": {\n",
    "        \"ACAV100M_sample\": 1024,\n",
    "        \"adversarial_negative\": 50,\n",
    "        \"positive\": 50,\n",
    "    },\n",
    "\n",
    "    \"model_type\": \"dnn\",\n",
    "    \"layer_size\": 32,\n",
    "\n",
    "    \"steps\": 50000,\n",
    "    \"max_negative_weight\": 1500,\n",
    "    \"target_false_positives_per_hour\": 0.2,\n",
    "    \"target_accuracy\": 0.7,\n",
    "    \"target_recall\": 0.5,\n",
    "}\n",
    "\n",
    "config_path = os.path.join(BASE_DIR, \"timoshka_config.yaml\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(f\"Config saved to {config_path}\")\n",
    "print()\n",
    "print(open(config_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготавливаем структуру директорий, которую ожидает train.py\n",
    "# openWakeWord ожидает:\n",
    "#   output_dir/тимошка/positive/  — позитивные WAV\n",
    "#   output_dir/тимошка/negative/  — негативные WAV (adversarial)\n",
    "\n",
    "phrase_dir = os.path.join(TRAINING_DIR, \"тимошка\")\n",
    "pos_link = os.path.join(phrase_dir, \"positive\")\n",
    "neg_link = os.path.join(phrase_dir, \"negative\")\n",
    "\n",
    "os.makedirs(phrase_dir, exist_ok=True)\n",
    "\n",
    "# Create symlinks to our data\n",
    "if os.path.exists(pos_link):\n",
    "    os.remove(pos_link)\n",
    "os.symlink(ALL_POSITIVE_DIR, pos_link)\n",
    "\n",
    "if os.path.exists(neg_link):\n",
    "    os.remove(neg_link)\n",
    "os.symlink(ALL_NEGATIVE_DIR, neg_link)\n",
    "\n",
    "print(f\"Positive → {pos_link} → {ALL_POSITIVE_DIR}\")\n",
    "print(f\"Negative → {neg_link} → {ALL_NEGATIVE_DIR}\")\n",
    "print(f\"\\nPositive samples: {len(os.listdir(pos_link))}\")\n",
    "print(f\"Negative samples: {len(os.listdir(neg_link))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content\n",
    "\n",
    "# Шаг 1: Аугментация (шум, реверберация, вариации скорости)\n",
    "# Пропускаем --generate_clips, т.к. мы уже сгенерировали сэмплы\n",
    "echo \"Starting augmentation...\"\n",
    "\n",
    "python openWakeWord/openwakeword/train.py \\\n",
    "    --training_config /content/timoshka/timoshka_config.yaml \\\n",
    "    --augment_clips \\\n",
    "    --overwrite\n",
    "\n",
    "echo \"\\nAugmentation complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content\n",
    "\n",
    "# Шаг 2: Обучение модели\n",
    "echo \"Starting training (this will take a while)...\"\n",
    "\n",
    "python openWakeWord/openwakeword/train.py \\\n",
    "    --training_config /content/timoshka/timoshka_config.yaml \\\n",
    "    --train_model\n",
    "\n",
    "echo \"\\nTraining complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 7: Конвертация в TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content\n",
    "\n",
    "# Конвертируем ONNX → TFLite\n",
    "python openWakeWord/openwakeword/train.py \\\n",
    "    --training_config /content/timoshka/timoshka_config.yaml \\\n",
    "    --convert_to_tflite\n",
    "\n",
    "echo \"\\nConversion complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим и показываем результат\n",
    "import glob\n",
    "\n",
    "tflite_files = glob.glob(os.path.join(TRAINING_DIR, \"**/*.tflite\"), recursive=True)\n",
    "onnx_files = glob.glob(os.path.join(TRAINING_DIR, \"**/*.onnx\"), recursive=True)\n",
    "\n",
    "print(\"Generated model files:\")\n",
    "for f in tflite_files + onnx_files:\n",
    "    size = os.path.getsize(f)\n",
    "    print(f\"  {f} ({size/1024:.1f} KB)\")\n",
    "\n",
    "# Copy the tflite to a convenient location\n",
    "if tflite_files:\n",
    "    final_path = os.path.join(BASE_DIR, \"timoshka.tflite\")\n",
    "    shutil.copy2(tflite_files[0], final_path)\n",
    "    print(f\"\\nFinal model: {final_path}\")\n",
    "    print(f\"Size: {os.path.getsize(final_path)/1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"\\nERROR: No .tflite file found. Check training logs above.\")\n",
    "    # Try manual conversion\n",
    "    if onnx_files:\n",
    "        print(f\"Found ONNX model at: {onnx_files[0]}\")\n",
    "        print(\"Try manual conversion in the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Резервная ручная конвертация ONNX → TFLite (если автоматическая не сработала)\n",
    "\n",
    "# import onnx\n",
    "# import tempfile\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "#\n",
    "# onnx_path = onnx_files[0]  # путь к ONNX модели\n",
    "# output_path = os.path.join(BASE_DIR, \"timoshka.tflite\")\n",
    "#\n",
    "# onnx_model = onnx.load(onnx_path)\n",
    "# tf_rep = prepare(onnx_model, device=\"CPU\")\n",
    "#\n",
    "# with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "#     tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
    "#     converter = tf.lite.TFLiteConverter.from_saved_model(\n",
    "#         os.path.join(tmp_dir, \"tf_model\")\n",
    "#     )\n",
    "#     tflite_model = converter.convert()\n",
    "#     with open(output_path, 'wb') as f:\n",
    "#         f.write(tflite_model)\n",
    "#\n",
    "# print(f\"Saved: {output_path} ({os.path.getsize(output_path)/1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 8: Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем модель на наших сэмплах\n",
    "from openwakeword.model import Model\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "model_path = os.path.join(BASE_DIR, \"timoshka.tflite\")\n",
    "oww_model = Model(wakeword_models=[model_path])\n",
    "model_name = list(oww_model.models.keys())[0]\n",
    "\n",
    "print(f\"Loaded model: {model_name}\")\n",
    "\n",
    "def test_wav(wav_path, model, name):\n",
    "    \"\"\"Test a single WAV file and return max score.\"\"\"\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    if sr != 16000:\n",
    "        waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    audio = (waveform.squeeze().numpy() * 32767).astype(np.int16)\n",
    "\n",
    "    model.reset()\n",
    "    chunk_size = 1280\n",
    "    max_score = 0.0\n",
    "    for i in range(0, len(audio) - chunk_size, chunk_size):\n",
    "        chunk = audio[i:i+chunk_size]\n",
    "        prediction = model.predict(chunk)\n",
    "        score = prediction[name]\n",
    "        max_score = max(max_score, score)\n",
    "    return max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Тест на позитивных сэмплах\n",
    "print(\"=\" * 50)\n",
    "print(\"POSITIVE SAMPLES (should trigger)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "pos_files = glob.glob(os.path.join(ALL_POSITIVE_DIR, \"*.wav\"))\n",
    "test_pos = random.sample(pos_files, min(50, len(pos_files)))\n",
    "\n",
    "pos_scores = []\n",
    "for f in test_pos:\n",
    "    score = test_wav(f, oww_model, model_name)\n",
    "    pos_scores.append(score)\n",
    "\n",
    "triggered = sum(1 for s in pos_scores if s >= 0.5)\n",
    "print(f\"Tested: {len(test_pos)} samples\")\n",
    "print(f\"Triggered (>0.5): {triggered}/{len(test_pos)} ({100*triggered/len(test_pos):.0f}%)\")\n",
    "print(f\"Mean score: {np.mean(pos_scores):.3f}\")\n",
    "print(f\"Min/Max: {np.min(pos_scores):.3f} / {np.max(pos_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест на негативных сэмплах\n",
    "print(\"=\" * 50)\n",
    "print(\"NEGATIVE SAMPLES (should NOT trigger)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "neg_files = glob.glob(os.path.join(ALL_NEGATIVE_DIR, \"*.wav\"))\n",
    "test_neg = random.sample(neg_files, min(100, len(neg_files)))\n",
    "\n",
    "neg_scores = []\n",
    "false_positives = []\n",
    "for f in test_neg:\n",
    "    score = test_wav(f, oww_model, model_name)\n",
    "    neg_scores.append(score)\n",
    "    if score >= 0.5:\n",
    "        false_positives.append((os.path.basename(f), score))\n",
    "\n",
    "print(f\"Tested: {len(test_neg)} samples\")\n",
    "print(f\"False positives (>0.5): {len(false_positives)}/{len(test_neg)} ({100*len(false_positives)/len(test_neg):.1f}%)\")\n",
    "print(f\"Mean score: {np.mean(neg_scores):.3f}\")\n",
    "print(f\"Min/Max: {np.min(neg_scores):.3f} / {np.max(neg_scores):.3f}\")\n",
    "\n",
    "if false_positives:\n",
    "    print(\"\\nFalse positive files:\")\n",
    "    for fname, score in sorted(false_positives, key=lambda x: -x[1])[:10]:\n",
    "        print(f\"  {fname}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводка\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tp_rate = sum(1 for s in pos_scores if s >= 0.5) / len(pos_scores) * 100\n",
    "fp_rate = len(false_positives) / len(test_neg) * 100\n",
    "\n",
    "print(f\"True positive rate:  {tp_rate:.0f}%\")\n",
    "print(f\"False positive rate: {fp_rate:.1f}%\")\n",
    "print()\n",
    "\n",
    "if tp_rate >= 70 and fp_rate < 5:\n",
    "    print(\"Model looks good! Ready for deployment.\")\n",
    "elif tp_rate >= 50:\n",
    "    print(\"Model is acceptable. Consider more training or data.\")\n",
    "else:\n",
    "    print(\"Model needs improvement. Try:\")\n",
    "    print(\"  - More diverse target voices\")\n",
    "    print(\"  - More training steps\")\n",
    "    print(\"  - Adjusting threshold (lower for more sensitivity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачивание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать через Colab\n",
    "from google.colab import files\n",
    "\n",
    "model_path = os.path.join(BASE_DIR, \"timoshka.tflite\")\n",
    "if os.path.exists(model_path):\n",
    "    files.download(model_path)\n",
    "    print(f\"Downloaded: timoshka.tflite ({os.path.getsize(model_path)/1024:.1f} KB)\")\n",
    "else:\n",
    "    print(\"Model file not found. Check training logs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой на Home Assistant\n",
    "\n",
    "После скачивания `timoshka.tflite`:\n",
    "\n",
    "```bash\n",
    "# 1. Копируем модель на сервер\n",
    "scp timoshka.tflite v@plex.local:/home/v/home-assistant/openwakeword-data/timoshka.tflite\n",
    "\n",
    "# 2. Модель подхватится контейнером openwakeword через volume mount\n",
    "#    Если используется /share/openwakeword/, копируем туда:\n",
    "#    scp timoshka.tflite v@plex.local:/home/v/home-assistant/homeassistant/share/openwakeword/timoshka.tflite\n",
    "\n",
    "# 3. Перезапускаем контейнер openwakeword\n",
    "ssh v@plex.local 'cd /home/v/home-assistant && docker compose restart openwakeword'\n",
    "\n",
    "# 4. В Home Assistant:\n",
    "#    Settings → Voice assistants → ваш ассистент → Wake word → выбрать \"timoshka\"\n",
    "#\n",
    "# ESPHome/Atom Echo менять НЕ нужно — wake word обрабатывается серверно.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
